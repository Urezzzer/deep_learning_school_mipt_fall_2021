{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Домашнее задание: Seq2Seq with Attention","metadata":{"id":"R_JEdyU2UxA3"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nimport numpy as np\n\nimport torchtext\nfrom torchtext.legacy.data import Field, BucketIterator\nfrom IPython.display import Markdown as md\nfrom nltk.tokenize import WordPunctTokenizer","metadata":{"id":"kiv7xYJLrJTh","execution":{"iopub.status.busy":"2021-11-08T13:17:00.717066Z","iopub.execute_input":"2021-11-08T13:17:00.717299Z","iopub.status.idle":"2021-11-08T13:17:03.338481Z","shell.execute_reply.started":"2021-11-08T13:17:00.717231Z","shell.execute_reply":"2021-11-08T13:17:03.337756Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"8n4BaVoJUxBI","outputId":"ff8eadeb-8b1f-4cf6-8978-4866e2007160","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /content/drive/MyDrive/ColabNotebooks/\nimport modules \nimport imp\nimp.reload(modules)","metadata":{"id":"uyXLTmKtUxBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 3\n\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"dvFT-Zm4j4z4","execution":{"iopub.status.busy":"2021-11-08T13:17:23.012357Z","iopub.execute_input":"2021-11-08T13:17:23.012647Z","iopub.status.idle":"2021-11-08T13:17:23.062381Z","shell.execute_reply.started":"2021-11-08T13:17:23.012616Z","shell.execute_reply":"2021-11-08T13:17:23.061606Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Data","metadata":{"id":"mNlmgpD4rJTr"}},{"cell_type":"code","source":"! wget https://drive.google.com/uc?id=1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_ -O data.txt","metadata":{"id":"hS19EMf-UxBK","execution":{"iopub.status.busy":"2021-11-08T13:17:31.939803Z","iopub.execute_input":"2021-11-08T13:17:31.940259Z","iopub.status.idle":"2021-11-08T13:17:34.058398Z","shell.execute_reply.started":"2021-11-08T13:17:31.940222Z","shell.execute_reply":"2021-11-08T13:17:34.057595Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer_W = WordPunctTokenizer()\n\ndef tokenize_ru(x, tokenizer=tokenizer_W):\n    return tokenizer.tokenize(x.lower())[::-1]\n\ndef tokenize_en(x, tokenizer=tokenizer_W):\n    return tokenizer.tokenize(x.lower())","metadata":{"id":"M3EqJeyorJTt","execution":{"iopub.status.busy":"2021-11-08T13:17:39.970108Z","iopub.execute_input":"2021-11-08T13:17:39.970416Z","iopub.status.idle":"2021-11-08T13:17:39.975878Z","shell.execute_reply.started":"2021-11-08T13:17:39.970377Z","shell.execute_reply":"2021-11-08T13:17:39.974785Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"SRC = Field(tokenize=tokenize_ru,\n            init_token = '<sos>', \n            eos_token = '<eos>', \n            lower = True)\n\nTRG = Field(tokenize=tokenize_en,\n            init_token = '<sos>', \n            eos_token = '<eos>', \n            lower = True)\n\n\ndataset = torchtext.legacy.data.TabularDataset(\n    path='data.txt',\n    format='tsv',\n    fields=[('trg', TRG), ('src', SRC)]\n)","metadata":{"id":"fVXeUedkrJT1","execution":{"iopub.status.busy":"2021-11-08T13:17:42.524251Z","iopub.execute_input":"2021-11-08T13:17:42.524990Z","iopub.status.idle":"2021-11-08T13:17:45.053240Z","shell.execute_reply.started":"2021-11-08T13:17:42.524949Z","shell.execute_reply":"2021-11-08T13:17:45.052471Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(len(dataset.examples))\nprint(dataset.examples[0].src)\nprint(dataset.examples[0].trg)","metadata":{"id":"RQ87fad2Qbjf","outputId":"cdf88d46-1027-45e0-c4d4-8c01cfed656d","execution":{"iopub.status.busy":"2021-11-08T13:17:45.658819Z","iopub.execute_input":"2021-11-08T13:17:45.659090Z","iopub.status.idle":"2021-11-08T13:17:45.665033Z","shell.execute_reply.started":"2021-11-08T13:17:45.659042Z","shell.execute_reply":"2021-11-08T13:17:45.664179Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n\nprint(f\"Number of training examples: {len(train_data.examples)}\")\nprint(f\"Number of validation examples: {len(valid_data.examples)}\")\nprint(f\"Number of testing examples: {len(test_data.examples)}\")","metadata":{"id":"i1fD5SPjzwpb","outputId":"da79f83f-82ac-43b3-d483-38fdff14138e","execution":{"iopub.status.busy":"2021-11-08T13:17:47.673029Z","iopub.execute_input":"2021-11-08T13:17:47.673654Z","iopub.status.idle":"2021-11-08T13:17:47.743914Z","shell.execute_reply.started":"2021-11-08T13:17:47.673618Z","shell.execute_reply":"2021-11-08T13:17:47.743081Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"SRC.build_vocab(train_data, min_freq = 2)\nTRG.build_vocab(train_data, min_freq = 2)","metadata":{"id":"dokjQsSWrJUL","execution":{"iopub.status.busy":"2021-11-08T13:17:52.814699Z","iopub.execute_input":"2021-11-08T13:17:52.815259Z","iopub.status.idle":"2021-11-08T13:17:53.621252Z","shell.execute_reply.started":"2021-11-08T13:17:52.815219Z","shell.execute_reply":"2021-11-08T13:17:53.620516Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(f\"Unique tokens in source vocabulary: {len(SRC.vocab)}\")\nprint(f\"Unique tokens in target vocabulary: {len(TRG.vocab)}\")","metadata":{"id":"1Q7f9pQVdfAk","outputId":"ec3873b5-a043-4d41-e408-7cb869347b50","execution":{"iopub.status.busy":"2021-11-08T14:15:24.460343Z","iopub.execute_input":"2021-11-08T14:15:24.462257Z","iopub.status.idle":"2021-11-08T14:15:24.470349Z","shell.execute_reply.started":"2021-11-08T14:15:24.462218Z","shell.execute_reply":"2021-11-08T14:15:24.469362Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(vars(train_data.examples[9]))","metadata":{"id":"IudJKJ-0rJU0","outputId":"19ace344-e1d1-4c33-a777-ee5360174dc9","execution":{"iopub.status.busy":"2021-11-08T13:17:56.301520Z","iopub.execute_input":"2021-11-08T13:17:56.302161Z","iopub.status.idle":"2021-11-08T13:17:56.307172Z","shell.execute_reply.started":"2021-11-08T13:17:56.302122Z","shell.execute_reply":"2021-11-08T13:17:56.306215Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\n\ntrain_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n    (train_data, valid_data, test_data), \n    batch_size = BATCH_SIZE, \n    device = device,\n    sort_key= lambda x: len(x.src)\n)","metadata":{"id":"PPekRL4arJVb","execution":{"iopub.status.busy":"2021-11-08T13:17:58.572381Z","iopub.execute_input":"2021-11-08T13:17:58.573093Z","iopub.status.idle":"2021-11-08T13:17:58.578904Z","shell.execute_reply.started":"2021-11-08T13:17:58.573055Z","shell.execute_reply":"2021-11-08T13:17:58.576930Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{"id":"wfHMFs00jXBZ"}},{"cell_type":"code","source":"Encoder = modules.Encoder\nAttention = modules.Attention\nDecoder = modules.DecoderWithAttention\nSeq2Seq = modules.Seq2Seq","metadata":{"id":"orrgzcOCzM6z","execution":{"iopub.status.busy":"2021-11-08T13:18:50.025477Z","iopub.execute_input":"2021-11-08T13:18:50.026172Z","iopub.status.idle":"2021-11-08T13:18:50.030824Z","shell.execute_reply.started":"2021-11-08T13:18:50.026131Z","shell.execute_reply":"2021-11-08T13:18:50.029618Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(SRC.vocab)\nOUTPUT_DIM = len(TRG.vocab)\nENC_EMB_DIM = 300\nDEC_EMB_DIM = 300\nHID_DIM = 512\nN_LAYERS = 2\nENC_DROPOUT = 0.1\nDEC_DROPOUT = 0.1\nBIDIRECTIONAL = True\nTEMPERATURE = 3\n\nenc = Encoder(INPUT_DIM, ENC_EMB_DIM, (HID_DIM // 2) * (1 + (not BIDIRECTIONAL)), N_LAYERS, ENC_DROPOUT, BIDIRECTIONAL)\nattention = Attention(HID_DIM, TEMPERATURE)\ndec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attention)\nmodel = Seq2Seq(enc, dec, device).to(device)","metadata":{"id":"J924jtXEjV9V","execution":{"iopub.status.busy":"2021-11-08T13:19:04.488867Z","iopub.execute_input":"2021-11-08T13:19:04.489381Z","iopub.status.idle":"2021-11-08T13:19:08.675773Z","shell.execute_reply.started":"2021-11-08T13:19:04.489343Z","shell.execute_reply":"2021-11-08T13:19:08.674866Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    for name, param in m.named_parameters():\n        nn.init.uniform_(param, -0.08, 0.08)\n        \nmodel.apply(init_weights)","metadata":{"id":"PbbzYM0hrJV1","outputId":"e9bbec08-f53a-4150-9251-11cc3f5706de","execution":{"iopub.status.busy":"2021-11-08T13:19:09.111184Z","iopub.execute_input":"2021-11-08T13:19:09.111520Z","iopub.status.idle":"2021-11-08T13:19:09.125783Z","shell.execute_reply.started":"2021-11-08T13:19:09.111487Z","shell.execute_reply":"2021-11-08T13:19:09.124937Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nmd('The model has **{:,}** trainable parameters'.format(count_parameters(model)))","metadata":{"id":"NuGicKW1rJV6","outputId":"b2646d5c-eb1d-4842-fd59-f6ddde545045","execution":{"iopub.status.busy":"2021-11-08T13:19:12.198410Z","iopub.execute_input":"2021-11-08T13:19:12.199161Z","iopub.status.idle":"2021-11-08T13:19:12.205817Z","shell.execute_reply.started":"2021-11-08T13:19:12.199120Z","shell.execute_reply":"2021-11-08T13:19:12.205068Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Train functions","metadata":{"id":"A8NjW0-Jrcvx"}},{"cell_type":"code","source":"import time\nimport math\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom tqdm.auto import tqdm\n\n\ndef get_text(x, trg_vocab):\n    id_sw = [trg_vocab.stoi['<unk>'], trg_vocab.stoi['<pad>'], trg_vocab.stoi['<sos>']]\n    id_eos = trg_vocab.stoi['<eos>']\n    ans = []\n\n    for sec in x:\n        if id_eos in sec:\n            sec = sec[:np.where(sec == id_eos)[0][0]]\n        sec = np.delete(sec, [x in id_sw for x in sec])\n        sec = [trg_vocab.itos[elem] for elem in sec]\n        ans.append(sec)\n\n    return np.array(ans, dtype=object)\n\n\ndef generate_translation(src, trg, model, trg_vocab):\n    model.eval()\n    output = model(src, trg, 0)\n    output = output[1:].argmax(-1)\n    original = get_text(trg.T.cpu().numpy(), trg_vocab)\n    generated = get_text(output.T.cpu().numpy(), trg_vocab)\n\n    for i in np.random.choice(len(original), 10):\n        print('Original: {}'.format(' '.join(original[i])))\n        print('Generated: {}'.format(' '.join(generated[i])))\n        print()\n\n\ndef bleu_metric(corpus, model, trg_vocab):\n    org_text, gen_text = [], []\n\n    model.eval()\n    with torch.no_grad():\n        for (trg, src), _ in tqdm(corpus, total=len(corpus)):\n            output = model(src, trg, 0)\n            output = output[1:].argmax(-1)\n            org_text.extend(get_text(trg.T.cpu().numpy(), trg_vocab))\n            gen_text.extend(get_text(output.T.cpu().numpy(), trg_vocab))\n\n    return corpus_bleu([[text] for text in org_text], gen_text) * 100\n\n\ndef show(log):\n    if len(log['time']) > 0:\n        n = len(log['time'])\n        m, s = log['time'][-1]\n        trn_loss, trn_ppl = log['trn_loss'][-1], math.exp(log['trn_loss'][-1])\n        val_loss, val_ppl, val_bleu = log['vld_loss'][-1], math.exp(log['vld_loss'][-1]), log['vld_bleu'][-1]\n    else:\n        n, m, s, trn_loss, trn_ppl, val_loss, val_ppl, val_bleu = 0, 0, 0, 0, 0, 0, 0, 0\n\n    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(18, 5))\n    clear_output(True)\n    fig.suptitle(\"Epoch {:02}: {}m {}s | Train loss: {:.2f}  PPL: {:4.1f} | Val loss: {:.2f}  PPL: {:4.1f}  BLEU: {:.2f}\".format(\n        n, m, s, trn_loss, trn_ppl, val_loss, val_ppl, val_bleu), fontsize=16)\n    ax[0].plot(list(range(1, len(log['trn_tmp']) + 1)), log['trn_tmp'], 'b', label='train loss')\n    ax[0].set_xlabel('Batch', fontsize=12)\n    ax[0].set_ylabel('Loss', fontsize=12)\n    ax[0].set_title('Current epoch loss (train)', fontsize=14)\n    if len(log['trn_loss']) > 0:\n        ax[1].plot(list(range(1, len(log['trn_loss']) + 1)), log['trn_loss'], 'bo-', label='train')\n        train_loss = log['trn_loss'][-1]\n    if len(log['vld_loss']) > 0:\n        ax[1].plot(list(range(1, len(log['vld_loss']) + 1)), log['vld_loss'], 'ro-', label='valid')\n        valid_loss = log['vld_loss'][-1]\n    ax[1].set_xlabel('Epoch', fontsize=12)\n    ax[1].set_title('Loss history', fontsize=14)\n    ax[1].set_ylabel('Loss', fontsize=12)\n    if len(log['time']) > 0:\n        ax[1].legend()\n    ax[2].plot(list(range(1, len(log['vld_bleu']) + 1)), log['vld_bleu'], 'ro-', label='valid')\n    ax[2].set_xlabel('Epoch', fontsize=12)\n    ax[2].set_ylabel('BLEU', fontsize=12)\n    ax[2].set_title('BLEU history (valid)', fontsize=14)\n    plt.show()\n\n\ndef train(model, iterator, optimizer, criterion, clip, tf_ratio, log=None):\n    model.train()\n    output_dim = model.decoder.output_dim\n    epoch_loss = 0\n    log['trn_tmp'] = []\n\n    for i, ((trg, src), _) in enumerate(iterator):\n        optimizer.zero_grad()\n        output = model(src, trg, tf_ratio)\n        output = output[1:].view(-1, output_dim)\n        trg = trg[1:].view(-1)\n        loss = criterion(output, trg)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        log['trn_tmp'].append(loss.cpu().item())\n\n        if (i + 1) % 10 == 0:\n            show(log)\n\n    return epoch_loss / len(iterator)\n\n\ndef evaluate(model, iterator, criterion, trg_vocab):\n    model.eval()\n    output_dim = model.decoder.output_dim\n    epoch_loss = 0\n    org_text, gen_text = [], []\n\n    with torch.no_grad():\n        for (trg, src), _ in iterator:\n            pred = model(src, trg, 0)\n            output = pred[1:].view(-1, output_dim)\n            trg_loss = trg[1:].view(-1)\n            loss = criterion(output, trg_loss)\n            epoch_loss += loss.item()\n\n            output = pred[1:].argmax(-1)\n            org_text.extend(get_text(trg.T.cpu().numpy(), trg_vocab))\n            gen_text.extend(get_text(output.T.cpu().numpy(), trg_vocab))\n\n    loss = epoch_loss / len(iterator)\n    bleu = corpus_bleu([[text] for text in org_text], gen_text) * 100\n\n    return loss, bleu\n\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n\n\ndef education(model, optimizer, scheduler, criterion, trg_vocab, trn_iter, val_iter, n_epoch=5, clip=5, tf_ratio=0.5):\n    best_valid_bleu = 0\n    log = {'trn_tmp': [], 'trn_loss': [], 'vld_loss': [], 'vld_bleu': [], 'time': []}\n\n    for epoch in range(n_epoch):\n        start_time = time.time()\n        train_loss = train(model, trn_iter, optimizer, criterion, clip, tf_ratio, log)\n        valid_loss, valid_bleu = evaluate(model, val_iter, criterion, trg_vocab)\n        scheduler.step()\n        end_time = time.time()\n        log['trn_loss'].append(train_loss)\n        log['vld_loss'].append(valid_loss)\n        log['vld_bleu'].append(valid_bleu)\n        log['time'].append(epoch_time(start_time, end_time))\n        show(log)\n\n        if valid_bleu > best_valid_bleu:\n            best_valid_bleu = valid_bleu\n            torch.save(model.state_dict(), 'best-val-model.pt')\n\n    return log","metadata":{"id":"vF7LIchgraQy","execution":{"iopub.status.busy":"2021-11-08T13:19:31.107829Z","iopub.execute_input":"2021-11-08T13:19:31.108279Z","iopub.status.idle":"2021-11-08T13:19:31.149647Z","shell.execute_reply.started":"2021-11-08T13:19:31.108239Z","shell.execute_reply":"2021-11-08T13:19:31.148842Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"h_relebep7M6"}},{"cell_type":"code","source":"N_EPOCHS = 15\nCLIP = 5\nTF_RATIO = 0.5\n\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)\nscheduler = StepLR(optimizer, step_size=12, gamma=0.1)\ncriterion = nn.CrossEntropyLoss(ignore_index = TRG.vocab.stoi['<pad>'])\n\nlog = education(model, optimizer, scheduler, criterion, TRG.vocab, train_iterator, valid_iterator, N_EPOCHS, CLIP, TF_RATIO)","metadata":{"id":"rY_84yH-rJWa","outputId":"2e860fa3-c456-488a-cb43-736d5963694c","execution":{"iopub.status.busy":"2021-11-08T13:19:37.047627Z","iopub.execute_input":"2021-11-08T13:19:37.048437Z","iopub.status.idle":"2021-11-08T14:15:10.898999Z","shell.execute_reply.started":"2021-11-08T13:19:37.048399Z","shell.execute_reply":"2021-11-08T14:15:10.898353Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Control quality","metadata":{"id":"jC6pFTn6rJWg"}},{"cell_type":"code","source":"model.load_state_dict(torch.load('best-val-model.pt'))\n(trg, src), _ = next(iter(test_iterator))\ngenerate_translation(src, trg, model, TRG.vocab)","metadata":{"id":"nfKBEGGo9zto","outputId":"c3860596-acbf-426a-a07c-0e7cb7a8ed8b","execution":{"iopub.status.busy":"2021-11-08T14:15:10.900538Z","iopub.execute_input":"2021-11-08T14:15:10.901116Z","iopub.status.idle":"2021-11-08T14:15:11.082110Z","shell.execute_reply.started":"2021-11-08T14:15:10.901077Z","shell.execute_reply":"2021-11-08T14:15:11.081348Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"bleu = bleu_metric(test_iterator, model, TRG.vocab)\nmd('**Bleu: {}**'.format(round(bleu, 2)))","metadata":{"id":"fezpjZTarJW1","outputId":"0cc79460-280c-42df-e742-4cac5d4039d9","execution":{"iopub.status.busy":"2021-11-08T14:15:11.083219Z","iopub.execute_input":"2021-11-08T14:15:11.083502Z","iopub.status.idle":"2021-11-08T14:15:24.456050Z","shell.execute_reply.started":"2021-11-08T14:15:11.083462Z","shell.execute_reply":"2021-11-08T14:15:24.455378Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## My Conclusion\n* information about your the results obtained \n* difference between seminar and homework model","metadata":{}},{"cell_type":"markdown","source":"Моя модель в отличии от семинарской имеет attention и поэтому показывает более высокие результаты. Для настройки модели понадобилось немало времени - пришлось перебрать большое количество параметров.\nТак же заметил, что нет прямой зависимости валидационного лосса от метрики, поэтому выводил ещё и её.","metadata":{}},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"bK4dt8YrpVDB"}}]}